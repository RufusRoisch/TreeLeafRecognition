The aim of our project was to test many different hyperparameter settings related to image recognition. 
Therefore, our project consists of several seperate scripts containing different ways to train the model, which can all be run individually.

Data:

LeafPicture naming convention: l<treeClassNr>nr<pictureNumber>
With picture Number = "001" - "075" representing the picture being the n'th of this type
And
TreeClassNr:
1: Ulmus carpinifolia / Feldulme
2: Acer / Ahorn
3: Salix aurita / Ohr-Weide
4: Quercus / Eiche
5: Alnus incana / Grau-Erle
6: Betula pubescens / Moor-Birke
7: Salix alba 'Sericea' / Silber-Weide
8: Populus tremula / Espe
9: Ulmus glabra / Bergulme
10: Sorbus aucuparia / Eberesche
11: Salix sinerea / Asch-Weide
12: Populus / Pappel
13: Tilia / Linde
14: Sorbus intermedia / Schwedische Mehlbeere
15: Fagus silvatica / Rotbuche

TO-DO:
- try adding pre-trained model
- try different layers
- try different image-scales (runtime vs accuracy)
- try greyscale instead of colored?
- try different amount of epochs

Run the scripts:
Possibly need to change directory path 

1) DownScaleImages.py
	Images need to be scaled to the same size --> Resized version of the images (150,300,3) can be found in the folder "LeafPicsDownScaled"
2) Color.py
	Change the color scheme of the input images (black and white/HSV)
3) main.py
	Contains the basemodel
4) Augmentation.py
	Based on the base model but uses additional data augmentation with the Image Data Generator
5) Pretrained.py --> Best model results
	Uses the weights of the VGG19 network architecture to train our base model
	


Transfer learning:

1) Images need to be resized to the first layer of the pretrained model (224,224,3)
2) No convolutions after pretrained model
2.1) Add flattened layer with the shape of the pretrained model (4096)
2.2) Afterwards only dense layer
3) Iterate backwards over the layer of the pretrained model and unfreeze them one after another